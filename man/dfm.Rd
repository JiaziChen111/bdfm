% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/dfm.R
\name{dfm}
\alias{dfm}
\title{Estimate a Dynamic Factor Model}
\usage{
dfm(data, factors = 1, lags = "auto", forecasts = 0,
  method = c("bayesian", "ml", "pc"), scale = TRUE, logs = "auto",
  diffs = "auto", outlier_threshold = 4, frequency_mix = "auto",
  pre_differenced = NULL, trans_prior = NULL, trans_shrink = 0,
  trans_df = 0, obs_prior = NULL, obs_shrink = 0, obs_df = NULL,
  identification = "pc_long", keep_posterior = NULL,
  interpolate = FALSE, orthogonal_shocks = FALSE, reps = 1000,
  burn = 500, verbose = interactive() &&
  !isTRUE(getOption("knitr.in.progress")), tol = 0.01)
}
\arguments{
\item{data}{one or multiple time series. The data to be used for estimation.
This can be entered as a \code{"ts"} object or as a matrix. If
\href{https://tsbox.help}{tsbox} is installed, any ts-boxable time series can be
supplied (\code{ts}, \code{xts}, \code{zoo}, \code{data.frame}, \code{data.table}, \code{tbl}, \code{tbl_ts},
\code{tbl_time}, or \code{timeSeries})}

\item{factors}{integer. The number of unobserved factors to be estimated. A
larger number of factors leads to a more complex model. Denoted as 'm'
in the documentation.}

\item{lags}{integer. The number of lags in the transition equation. If
\code{"auto"} (default), the number is equal to highest frequency in \code{data}.
Denoted as 'p' in the documentation.}

\item{forecasts}{integer. Number of periods ahead to forecasts.}

\item{method}{character. Method to be used; one of \code{"bayesian"}, \code{"ml"} or
\code{"pc"}. See details.}

\item{scale}{logical. Should data be scaled before estimation? \code{TRUE}
(default) resolves some numerical problems during estimation. \code{FALSE}
ensures that the coefficient estimates are interpretable.}

\item{logs}{names or index values (see details). Series of which the
logarithm is taken (can be combined with \code{diffs}). If \code{"auto"} (default)
this is done for all series that are differentiated and have no values < 0.}

\item{diffs}{names or index values (see details). Series to be
differentiated. If \code{"auto"} (default), a modified Durbin-Watson test is
performed.}

\item{outlier_threshold}{integer. Observations more than \code{outlier_threshold}
standard deviations from the series mean are removed. This is useful to
increase the stability of the estimation.}

\item{frequency_mix}{integer or \code{"auto"}. Number of high frequency periods
in a low frequency period. If \code{"auto"} (default), this is inferred from the
time series.}

\item{pre_differenced}{names or index values (see details). series entered in
differences (If series are specified in \code{diffs}, this is not needed.)}

\item{trans_prior}{m x mp (m: factors, p: lags) prior matrix for B (the transition matrix) in the transition equation. Default is
zeros. E.g., to use a random walk prior with m factors and p lags, set
\code{trans_prior = cbind(diag(1,m,m), matrix(0,m,m*(p-1)))}.}

\item{trans_shrink}{numeric. Prior tightness on B matrix in transition equation where a value of zero is
used to denote an improper (flat) prior (i.e. no shrinkage). Use
to shrink forecast values towards the prior \code{trans_prior},
which may help reduce parameter uncertainty in estimation.}

\item{trans_df}{numeric. Prior degrees of freedom for inverse-Wishart distribution of shocks
in the transition equation, where 0 implies no shrinkage.
Shrinking shocks to the transition equation will increase the magnitude
of shocks to the observation equation dampening updates from observed
series. High values of \code{trans_df} can lead to
instability in simulations.}

\item{obs_prior}{k x m (k: observed series, m: factors) prior matrix for H (loadings) in the observation equation
Default is zeros.}

\item{obs_shrink}{numeric. Prior tightness on H (loadings) in the observation
equation where a value of zero is
used to denote an improper (flat) prior (i.e. no shrinkage). A greater value will shrink estimates of loadings more
aggressively towards the prior \code{obs_prior}. When the prior is zero (the
default value), this is an alternative (and typically more stable) approach
to dampening the impact of updates from observed series.}

\item{obs_df}{named vector (see details). prior degrees of freedom
for inverse chi-squared distribution in the observation equation. This is useful to give
specific series a larger weight, e.g. 1. (default 0).}

\item{identification}{names or index values (see details), or character.
Factor identification. \code{"pc_long"} (default) identifies on principal components
from series with at least the median number of observations. \code{"pc_wide"}
identifies on principal components using all series, where rows of the observations
matrix containing missing data are omitted. \code{"name"} uses Stock and Watson's "naming
factors" identification, i.e. identifying on the first m series provided where m is the
number of factors. Identification can also be done manually, by supplying names or index
values from which identifying series are derived via principal components.}

\item{keep_posterior}{names or index values (see details). Series of which to
keep the full posterior distribution of predicted values (method
\code{"bayesian"} only). This is useful for forecasting as the posterior median forecast
value tends to me more accurate than forecasts using the posterior median parameter
estimates, and allows for the evaluation of forecast accuracy.}

\item{interpolate}{logical. Should output return intra-frequency estimates of low
frequency observables? Put differently, if the model includes monthly and quarterly data,
should output include
estimates of quarterly data every month (where quarterly refers to an aggregate of the
current and previous 2 months; for \code{interpolate = TRUE}) or just at the end of the quarter (months 3, 6, 9, and 12;
for \code{interpolate = FALSE}, default)?}

\item{orthogonal_shocks}{logical. Return a rotation of the model with orthogonal
shocks and factors. This is used to isolate the impact of each factor on observables,
allowing for a clean interpretation of how shocks (which, if \code{TRUE} are not correlated)
impact observed series.}

\item{reps}{integer. Number of repetitions for MCMC sampling}

\item{burn}{integer. Number of iterations to burn in MCMC sampling}

\item{verbose}{logical. Print status of function during evaluation. Default is
\code{TRUE} in interactive mode, \code{FALSE} otherwise, so it does not appear, e.g.,
in \code{reprex::reprex()}.}

\item{tol}{numeric. Tolerance for convergence of EM algorithm (method \code{"ml"}
only). The default value is 0.01 which corresponds to the convergence
criteria used in Doz, Giannone, and Reichlin (2012).}
}
\description{
Estimates a Bayesian or non-Bayesian dynamic factor Model. With the default
options, \code{dfm} calls  automatic procedures that works well in many
circumstances.
}
\details{
\strong{Specifying series}: Individual series can be specified either by \emph{names}
(recommended) or index values. An index value refers to the position of the
series in \code{data}.

\strong{Specifying parameters for specific series}: Parameters for individual
series can be specified using a \emph{named} vector (recommended) or using a
unnamed vector of the same length as as the number of series in \code{data}.
}
\examples{

dta <- cbind(fdeaths, mdeaths)

m0 <- dfm(dta, forecast = 2) # estimation with 2 period forecast
predict(m0)                  # series with imputations and forecasts
summary(m0)                  # summary of the model
factors(m0)                  # estimated factor

# informative priors: giving 'fdeaths' a higher weight
m1 <- dfm(dta, obs_df = c("fdeaths" = 1))
summary(m1)

\dontrun{
# Forecasting U.S. GDP
m1 <- dfm(econ_us,
  pre_differenced = "A191RL1Q225SBEA",
  keep_posterior = "A191RL1Q225SBEA"
)

# interpolating low frequency series
dta_mixed <- econ_us[, c(1, 3)]
predict(dfm(dta_mixed))
predict(dfm(dta_mixed, interpolate = TRUE))
}
}
\seealso{
\code{vignette("dfm")}, for a more comprehensive intro to the package.

\href{http://srlquantitative.com/docs/Factor_Models.pdf}{Practical Implementation of Factor Models} for a comprehensive overview of dynamic factor models.
}
